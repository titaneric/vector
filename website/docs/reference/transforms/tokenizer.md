---
component_title: "Tokenizer"
description: "The Vector `tokenizer` transform accepts and outputs `log` events allowing you to tokenize a field's value by splitting on white space, ignoring special wrapping characters, and zip the tokens into ordered field names."
event_types: ["log"]
function_category: "parse"
issues_url: https://github.com/timberio/vector/issues?q=is%3Aopen+is%3Aissue+label%3A%22transform%3A+tokenizer%22
min_version: null
service_name: "Tokenizer"
sidebar_label: "tokenizer|[\"log\"]"
source_url: https://github.com/timberio/vector/tree/master/src/transforms/tokenizer.rs
status: "prod-ready"
title: "Tokenizer Transform"
---

The Vector `tokenizer` transform
accepts and outputs [`log`][docs.data-model.log] events allowing you to
tokenize a field's value by splitting on white space, ignoring special wrapping
characters, and zip the tokens into ordered field names.

<!--
     THIS FILE IS AUTOGENERATED!

     To make changes please edit the template located at:

     website/docs/reference/transforms/tokenizer.md.erb
-->

## Configuration

import CodeHeader from '@site/src/components/CodeHeader';

<CodeHeader fileName="vector.toml" learnMoreUrl="/docs/setup/configuration/"/ >

```toml
[transforms.my_transform_id]
  # General
  type = "tokenizer" # required
  inputs = ["my-source-id"] # required
  field_names = ["timestamp", "level", "message", "parent.child"] # required
  drop_field = true # optional, default
  field = "message" # optional, default

  # Types
  types.status = "int" # example
  types.duration = "float" # example
  types.success = "bool" # example
  types.timestamp = "timestamp|%F" # example
  types.timestamp = "timestamp|%a %b %e %T %Y" # example
  types.parent.child = "int" # example
```

## Options

import Fields from '@site/src/components/Fields';

import Field from '@site/src/components/Field';

<Fields filters={true}>


<Field
  common={true}
  defaultValue={true}
  enumValues={null}
  examples={[true,false]}
  groups={[]}
  name={"drop_field"}
  path={null}
  relevantWhen={null}
  required={false}
  templateable={false}
  type={"bool"}
  unit={null}
  >

### drop_field

If `true` the [`field`](#field) will be dropped after parsing.




</Field>


<Field
  common={true}
  defaultValue={"message"}
  enumValues={null}
  examples={["message","parent.child"]}
  groups={[]}
  name={"field"}
  path={null}
  relevantWhen={null}
  required={false}
  templateable={false}
  type={"string"}
  unit={null}
  >

### field

The log field to tokenize.

 See [Field Notation Syntax](#field-notation-syntax) for more info.


</Field>


<Field
  common={true}
  defaultValue={null}
  enumValues={null}
  examples={[["timestamp","level","message","parent.child"]]}
  groups={[]}
  name={"field_names"}
  path={null}
  relevantWhen={null}
  required={true}
  templateable={false}
  type={"[string]"}
  unit={null}
  >

### field_names

The log field names assigned to the resulting tokens, in order.

 See [Field Notation Syntax](#field-notation-syntax) for more info.


</Field>


<Field
  common={true}
  defaultValue={null}
  enumValues={null}
  examples={[]}
  groups={[]}
  name={"types"}
  path={null}
  relevantWhen={null}
  required={false}
  templateable={false}
  type={"table"}
  unit={null}
  >

### types

Key/value pairs representing mapped log field names and types. This is used to
coerce log fields into their proper types.



<Fields filters={false}>


<Field
  common={true}
  defaultValue={null}
  enumValues={{"bool":"Coerces `\"true\"`/`/\"false\"`, `\"1\"`/`\"0\"`, and `\"t\"`/`\"f\"` values into boolean.","float":"Coerce to a 64 bit float.","int":"Coerce to a 64 bit integer.","string":"Coerce to a string.","timestamp":"Coerces to a Vector timestamp. [`strptime` specificiers][urls.strptime_specifiers] must be used to parse the string."}}
  examples={[{"status":"int"},{"duration":"float"},{"success":"bool"},{"timestamp":"timestamp|%F"},{"timestamp":"timestamp|%a %b %e %T %Y"},{"parent":{"child":"int"}}]}
  groups={[]}
  name={"`[field-name]`"}
  path={"types"}
  relevantWhen={null}
  required={false}
  templateable={false}
  type={"string"}
  unit={null}
  >

#### `[field-name]`

A definition of log field type conversions. They key is the log field name and
the value is the type. [`strptime` specifiers][urls.strptime_specifiers] are
supported for the `timestamp` type.




</Field>


</Fields>

</Field>


</Fields>

## Output

Given the following log line:

```json
{
  "message": "5.86.210.12 - zieme4647 [19/06/2019:17:20:49 -0400] "GET /embrace/supply-chains/dynamic/vertical" 201 20574"
}
```

And the following configuration:

```toml
[transforms.<transform-id>]
type = "tokenizer"
field = "message"
fields = ["remote_addr", "ident", "user_id", "timestamp", "message", "status", "bytes"]
```

A [`log` event][docs.data-model.log] will be output with the following structure:

```javascript
{
  // ... existing fields
  "remote_addr": "5.86.210.12",
  "user_id": "zieme4647",
  "timestamp": "19/06/2019:17:20:49 -0400",
  "message": "GET /embrace/supply-chains/dynamic/vertical",
  "status": "201",
  "bytes": "20574"
}
```

A few things to note about the output:

1. The `message` field was overwritten.
2. The `ident` field was dropped since it contained a `"-"` value.
3. All values are strings, we have plans to add type coercion.
4. [Special wrapper characters](#special-characters) were dropped, such as
   wrapping `[...]` and `"..."` characters.

## How It Works

### Blank Values

Both `" "` and `"-"` are considered blank values and their mapped field will
be set to `null`.

### Complex Processing

If you encounter limitations with the `tokenizer`
transform then we recommend using a [runtime transform][urls.vector_programmable_transforms].
These transforms are designed for complex processing and give you the power of
full programming runtime.

### Environment Variables

Environment variables are supported through all of Vector's configuration.
Simply add `${MY_ENV_VAR}` in your Vector configuration file and the variable
will be replaced before being evaluated.

You can learn more in the
[Environment Variables][docs.configuration#environment-variables] section.

### Field Notation Syntax

The [`field`](#field) and [`field_names`](#field_names) options
support [Vector's field notiation syntax][docs.reference.field-path-notation],
enabling access to root-level, nested, and array field values. For example:

<CodeHeader fileName="vector.toml" />

```toml
[transforms.my_tokenizer_transform_id]
  # ...
  field = "message"
  field = "parent.child"
  # ...
```

You can learn more about Vector's field notation in the
[field notation reference][docs.reference.field-path-notation].

### Special Characters

In order to extract raw values and remove wrapping characters, we must treat
certain characters as special. These characters will be discarded:

* `"..."` - Quotes are used tp wrap phrases. Spaces are preserved, but the wrapping quotes will be discarded.
* `[...]` - Brackets are used to wrap phrases. Spaces are preserved, but the wrapping brackets will be discarded.
* `\` - Can be used to escape the above characters, Vector will treat them as literal.


[docs.configuration#environment-variables]: /docs/setup/configuration/#environment-variables
[docs.data-model.log]: /docs/about/data-model/log/
[docs.reference.field-path-notation]: /docs/reference/field-path-notation/
[urls.strptime_specifiers]: https://docs.rs/chrono/0.3.1/chrono/format/strftime/index.html
[urls.vector_programmable_transforms]: https://vector.dev/components?functions%5B%5D=program
