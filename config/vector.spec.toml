#                                    __   __  __
#                                    \ \ / / / /
#                                     \ V / / /
#                                      \_/  \/
#
#                                    V E C T O R
#                            Configuration Specification
#
# ------------------------------------------------------------------------------
# Website: https://vector.dev
# Docs: https://vector.dev/docs/
# Community: https://vector.dev/community
# ------------------------------------------------------------------------------
# The file contains a full specification for the `vector.toml` configuration
# file. It follows the TOML format and includes all options, types, and
# possible values.
#
# More info on Vector's configuration can be found at:
# /docs/setup/configuration/

# ------------------------------------------------------------------------------
# Global
# ------------------------------------------------------------------------------
# Global options are relevant to Vector as a whole and apply to global behavior.

# The directory used for persisting Vector state, such as on-disk buffers, file
# checkpoints, and more. Please make sure the Vector project has write
# permissions to this dir.
#
# * optional
# * no default
# * type: string
data_dir = "/var/lib/vector"

# The list of DNS servers Vector will use to resolve DNS requests. When set
# Vector will ignore the system configuration and use only the list of DNS
# servers provided. If this option is not set then Vector will attempt to use
# the system configuration.
#
# * optional
# * no default
# * type: [string]
dns_servers = ["0.0.0.0:53"]

# ------------------------------------------------------------------------------
# Sources
# ------------------------------------------------------------------------------
# Sources specify data sources and are responsible for ingesting data into
# Vector.

# Ingests data through the docker engine daemon and outputs `log` events.
[sources.docker]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `docker`.
  #
  # * required
  # * type: string
  # * must be: "docker"
  type = "docker"

  # A list of container IDs _or_ names to match against. Prefix matches are
  # supported, meaning you can supply just the first few characters of the
  # container ID or name. If not provided, all containers will be included.
  #
  # * optional
  # * no default
  # * type: [string]
  include_containers = ["my_container_name", "container_prefix", "9b6247364a03"]

  # A list of image names to match against. If not provided, all images will be
  # included.
  #
  # * optional
  # * no default
  # * type: [string]
  include_images = ["my_image_name", "httpd", "redis"]

  # A list of container object labels to match against when filtering running
  # containers. This should follow the described label's synatx in docker object
  # labels docs.
  #
  # * optional
  # * no default
  # * type: [string]
  include_labels = ["label_key1=label_value1", "label_key2=label_value2"]

# Ingests data through one or more local files and outputs `log` events.
[sources.file]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `file`.
  #
  # * required
  # * type: string
  # * must be: "file"
  type = "file"

  # Delay between file discovery calls. This controls the interval at which
  # Vector searches for files.
  #
  # * required
  # * default: 1000
  # * type: int
  # * unit: milliseconds
  glob_minimum_cooldown = 1000

  # Array of file patterns to include. Globbing is supported.
  #
  # * required
  # * type: [string]
  include = ["/var/log/nginx/*.log"]

  # For files with a stored checkpoint at startup, setting this option to `true`
  # will tell Vector to read from the beginning of the file instead of the stored
  # checkpoint.
  #
  # * required
  # * default: false
  # * type: bool
  start_at_beginning = false
  start_at_beginning = true

  # The directory used to persist file checkpoint positions. By default, the
  # global `data_dir` option is used. Please make sure the Vector project has
  # write permissions to this dir.
  #
  # * optional
  # * no default
  # * type: string
  data_dir = "/var/lib/vector"

  # Array of file patterns to exclude. Globbing is supported.*Takes precedence
  # over the `include` option.*
  #
  # * optional
  # * no default
  # * type: [string]
  exclude = ["/var/log/nginx/*.[0-9]*.log"]

  # Ignore files with a data modification date that does not exceed this age.
  #
  # * optional
  # * no default
  # * type: int
  # * unit: seconds
  ignore_older = 86400

  # The maximum number of a bytes a line can contain before being discarded. This
  # protects against malformed lines or tailing incorrect files.
  #
  # * optional
  # * default: 102400
  # * type: int
  # * unit: bytes
  max_line_bytes = 102400

  #
  # Context
  #

  # The key name added to each event with the full path of the file.
  #
  # * required
  # * default: "file"
  # * type: string
  file_key = "file"

  # The key name added to each event representing the current host.
  #
  # * required
  # * default: "host"
  # * type: string
  host_key = "host"

  #
  # Multi-line
  #

  # When present, Vector will aggregate multiple lines into a single event, using
  # this pattern as the indicator that the previous lines should be flushed and a
  # new event started. The pattern will be matched against entire lines as a
  # regular expression, so remember to anchor as appropriate.
  #
  # * optional
  # * no default
  # * type: string
  message_start_indicator = "^(INFO|ERROR)"

  # When `message_start_indicator` is present, this sets the amount of time
  # Vector will buffer lines into a single event before flushing, regardless of
  # whether or not it has seen a line indicating the start of a new message.
  #
  # * optional
  # * default: 1000
  # * type: int
  # * unit: milliseconds
  multi_line_timeout = 1000

  #
  # Priority
  #

  # An approximate limit on the amount of data read from a single file at a given
  # time.
  #
  # * optional
  # * default: 2048
  # * type: int
  # * unit: bytes
  max_read_bytes = 2048

  # Instead of balancing read capacity fairly across all watched files,
  # prioritize draining the oldest files before moving on to read data from
  # younger files.
  #
  # * optional
  # * default: false
  # * type: bool
  oldest_first = false
  oldest_first = true

  #
  # Fingerprinting
  #

  [sources.file.fingerprinting]
    # The number of bytes read off the head of the file to generate a unique
    # fingerprint.
    #
    # * required
    # * default: 256
    # * type: int
    # * unit: bytes
    # * relevant when strategy = "checksum"
    fingerprint_bytes = 256

    # The number of bytes to skip ahead (or ignore) when generating a unique
    # fingerprint. This is helpful if all files share a common header.
    #
    # * required
    # * default: 0
    # * type: int
    # * unit: bytes
    # * relevant when strategy = "checksum"
    ignored_header_bytes = 0

    # The strategy used to uniquely identify files. This is important for
    # checkpointing when file rotation is used.
    #
    # * optional
    # * default: "checksum"
    # * type: string
    # * enum: "checksum" or "device_and_inode"
    strategy = "checksum"
    strategy = "device_and_inode"

# Ingests data through log records from journald and outputs `log` events.
[sources.journald]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `journald`.
  #
  # * required
  # * type: string
  # * must be: "journald"
  type = "journald"

  # The systemd journal is read in batches, and a checkpoint is set at the end of
  # each batch. This option limits the size of the batch.
  #
  # * optional
  # * default: 16
  # * type: int
  batch_size = 16

  # Include only entries from the current boot.
  #
  # * optional
  # * default: true
  # * type: bool
  current_boot_only = true
  current_boot_only = false

  # The directory used to persist the journal checkpoint position. By default,
  # the global `data_dir` is used. Please make sure the Vector project has write
  # permissions to this dir.
  #
  # * optional
  # * no default
  # * type: string
  data_dir = "/var/lib/vector"

  # The full path of the `journalctl` executable. If not set, Vector will search
  # the path for `journalctl`.
  #
  # * optional
  # * default: "journalctl"
  # * type: string
  journalctl_path = "/usr/local/bin/journalctl"

  # The list of units names to monitor. If empty or not present, all units are
  # accepted. Unit names lacking a `"."` will have `".service"` appended to make
  # them a valid service unit name.
  #
  # * optional
  # * default: []
  # * type: [string]
  units = ["ntpd", "sysinit.target"]

# Ingests data through Kafka 0.9 or later and outputs `log` events.
[sources.kafka]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `kafka`.
  #
  # * required
  # * type: string
  # * must be: "kafka"
  type = "kafka"

  # A comma-separated list of host and port pairs that are the addresses of the
  # Kafka brokers in a "bootstrap" Kafka cluster that a Kafka client connects to
  # initially to bootstrap itself.
  #
  # * required
  # * type: string
  bootstrap_servers = "10.14.22.123:9092,10.14.23.332:9092"

  # The consumer group name to be used to consume events from Kafka.
  #
  # * required
  # * type: string
  group_id = "consumer-group-name"

  # The Kafka topics names to read events from. Regex is supported if the topic
  # begins with `^`.
  #
  # * required
  # * type: [string]
  topics = ["^(prefix1|prefix2)-.+", "topic-1", "topic-2"]

  # If offsets for consumer group do not exist, set them using this strategy.
  # librdkafka documentation for `auto.offset.reset` option for explanation.
  #
  # * optional
  # * default: "largest"
  # * type: string
  auto_offset_reset = "smallest"
  auto_offset_reset = "earliest"
  auto_offset_reset = "beginning"
  auto_offset_reset = "largest"
  auto_offset_reset = "latest"
  auto_offset_reset = "end"
  auto_offset_reset = "error"

  # The log field name to use for the topic key. If unspecified, the key would
  # not be added to the log event. If the message has null key, then this field
  # would not be added to the log event.
  #
  # * optional
  # * no default
  # * type: string
  key_field = "user_id"

  # The Kafka session timeout in milliseconds.
  #
  # * optional
  # * default: 10000
  # * type: int
  # * unit: milliseconds
  session_timeout_ms = 5000
  session_timeout_ms = 10000

# Ingests data through the Heroku Logplex HTTP Drain protocol and outputs `log` events.
[sources.logplex]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `logplex`.
  #
  # * required
  # * type: string
  # * must be: "logplex"
  type = "logplex"

  # The address to accept connections on. The address _must_ include a port.
  #
  # * required
  # * type: string
  address = "0.0.0.0:8088"

# Ingests data through the Prometheus text exposition format and outputs `metric` events.
[sources.prometheus]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `prometheus`.
  #
  # * required
  # * type: string
  # * must be: "prometheus"
  type = "prometheus"

  # Host addresses to scrape metrics from.
  #
  # * required
  # * type: [string]
  hosts = ["http://localhost:9090"]

  # The interval between scrapes in seconds.
  #
  # * required
  # * type: int
  scrape_interval_secs = 1

# Ingests data through a socket, such as a TCP, UDP, or Unix socket and outputs `log` events.
[sources.socket]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `socket`.
  #
  # * required
  # * type: string
  # * must be: "socket"
  type = "socket"

  # The address to listen for connections on, or `systemd#N` to use the Nth
  # socket passed by systemd socket activation. If an address is used it _must_
  # include a port.
  #
  # * required
  # * type: string
  # * relevant when mode = "tcp" or mode = "udp"
  address = "0.0.0.0:9000"
  address = "systemd"
  address = "systemd#3"

  # The type of socket to use.
  #
  # * required
  # * type: string
  # * enum: "tcp", "udp", and "unix"
  mode = "tcp"
  mode = "udp"
  mode = "unix"

  # The timeout before a connection is forcefully closed during shutdown.
  #
  # * required
  # * default: 30
  # * type: int
  # * unit: seconds
  # * relevant when mode = "tcp"
  shutdown_timeout_secs = 30

  # The maximum bytes size of incoming messages before they are discarded.
  #
  # * optional
  # * default: 102400
  # * type: int
  # * unit: bytes
  max_length = 102400

  # The unix socket path. *This should be absolute path*.
  #
  # * optional
  # * no default
  # * type: string
  # * relevant when mode = "unix"
  path = "/path/to/socket"

  #
  # Context
  #

  # The key name added to each event representing the current host.
  #
  # * required
  # * default: "host"
  # * type: string
  host_key = "host"

# Ingests data through the Splunk HTTP Event Collector protocol and outputs `log` events.
[sources.splunk_hec]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `splunk_hec`.
  #
  # * required
  # * type: string
  # * must be: "splunk_hec"
  type = "splunk_hec"

  # The address to accept connections on.
  #
  # * required
  # * default: "0.0.0.0:8088"
  # * type: string
  address = "0.0.0.0:8088"

  # If supplied, incoming requests must supply this token in the `Authorization`
  # header, just as a client would if it was communicating with the Splunk HEC
  # endpoint directly. If _not_ supplied, the `Authorization` header will be
  # ignored and requests will not be authenticated.
  #
  # * optional
  # * no default
  # * type: string
  token = "A94A8FE5CCB19BA61C4C08"

# Ingests data through the StatsD UDP protocol and outputs `metric` events.
[sources.statsd]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `statsd`.
  #
  # * required
  # * type: string
  # * must be: "statsd"
  type = "statsd"

  # UDP socket address to bind to.
  #
  # * required
  # * type: string
  address = "127.0.0.1:8126"

# Ingests data through standard input (STDIN) and outputs `log` events.
[sources.stdin]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `stdin`.
  #
  # * required
  # * type: string
  # * must be: "stdin"
  type = "stdin"

  # The maxiumum bytes size of a message before it is discarded.
  #
  # * optional
  # * default: 102400
  # * type: int
  # * unit: bytes
  max_length = 102400

  #
  # Context
  #

  # The key name added to each event representing the current host.
  #
  # * required
  # * default: "host"
  # * type: string
  host_key = "host"

# Ingests data through the Syslog 5424 protocol and outputs `log` events.
[sources.syslog]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `syslog`.
  #
  # * required
  # * type: string
  # * must be: "syslog"
  type = "syslog"

  # The input mode.
  #
  # * required
  # * type: string
  # * enum: "tcp", "udp", and "unix"
  mode = "tcp"
  mode = "udp"
  mode = "unix"

  # The TCP or UDP address to listen for connections on, or "systemd#N" to use
  # the Nth socket passed by systemd socket activation.
  #
  # * optional
  # * no default
  # * type: string
  # * relevant when mode = "tcp" or mode = "udp"
  address = "0.0.0.0:9000"
  address = "systemd"
  address = "systemd#2"

  # The maximum bytes size of incoming messages before they are discarded.
  #
  # * optional
  # * default: 102400
  # * type: int
  # * unit: bytes
  max_length = 102400

  # The unix socket path. *This should be absolute path.*
  #
  # * optional
  # * no default
  # * type: string
  # * relevant when mode = "unix"
  path = "/path/to/socket"

  #
  # Context
  #

  # The key name added to each event representing the current host.
  #
  # * required
  # * default: "host"
  # * type: string
  host_key = "host"

# Ingests data through another upstream `vector` sink and outputs `log` and `metric` events.
[sources.vector]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `vector`.
  #
  # * required
  # * type: string
  # * must be: "vector"
  type = "vector"

  # The TCP address to listen for connections on, or `systemd#N to use the Nth
  # socket passed by systemd socket activation. If an address is used it _must_
  # include a port.
  #
  # * required
  # * type: string
  address = "0.0.0.0:9000"
  address = "systemd"
  address = "systemd#1"

  # The timeout before a connection is forcefully closed during shutdown.
  #
  # * required
  # * default: 30
  # * type: int
  # * unit: seconds
  shutdown_timeout_secs = 30


# ------------------------------------------------------------------------------
# Transforms
# ------------------------------------------------------------------------------
# Transforms parse, structure, and enrich events.

# Accepts `log` events and allows you to add one or more log fields.
[transforms.add_fields]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `add_fields`.
  #
  # * required
  # * type: string
  # * must be: "add_fields"
  type = "add_fields"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  #
  # Fields
  #

  [transforms.add_fields.fields]
    # The name of the field to add. Accepts all supported types. Use `.` for adding
    # nested fields.
    #
    # * required
    # * type: *
    string_field = "string value"
    env_var_field = "${ENV_VAR}"
    int_field = 1
    float_field = 1.2
    bool_field = true
    timestamp_field = 1979-05-27T00:32:00Z
    parent = {child = "child_value"}
    list_field = ["first", "second", "third"]

# Accepts `metric` events and allows you to add one or more metric tags.
[transforms.add_tags]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `add_tags`.
  #
  # * required
  # * type: string
  # * must be: "add_tags"
  type = "add_tags"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  #
  # Tags
  #

  [transforms.add_tags.tags]
    # The name of the tag to add. Due to the nature of metric tags, the value must
    # be a string.
    #
    # * required
    # * type: string
    static_tag = "my value"
    env_tag = "${ENV_VAR}"

# Accepts `log` events and allows you to strips ANSI characters from the specified field.
[transforms.ansi_stripper]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `ansi_stripper`.
  #
  # * required
  # * type: string
  # * must be: "ansi_stripper"
  type = "ansi_stripper"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The target field to strip ANSI characters from.
  #
  # * required
  # * default: "message"
  # * type: string
  field = "message"

# Accepts `log` events and allows you to enrich logs with AWS EC2 instance metadata.
[transforms.aws_ec2_metadata]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `aws_ec2_metadata`.
  #
  # * required
  # * type: string
  # * must be: "aws_ec2_metadata"
  type = "aws_ec2_metadata"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # A list of fields to include in each event.
  #
  # * optional
  # * default: ["instance-id", "local-hostname", "local-ipv4", "public-hostname", "public-ipv4", "ami-id", "availability-zone", "vpc-id", "subnet-id", "region"]
  # * type: [string]
  fields = ["instance-id", "local-hostname", "local-ipv4", "public-hostname", "public-ipv4", "ami-id", "availability-zone", "vpc-id", "subnet-id", "region"]

  # Override the default EC2 Metadata host.
  #
  # * optional
  # * default: "http://169.254.169.254"
  # * type: string
  host = "http://169.254.169.254"

  # Prepend a namespace to each field's key.
  #
  # * optional
  # * default: ""
  # * type: string
  namespace = ""

  # The interval in seconds at which the EC2 Metadata api will be called.
  #
  # * optional
  # * default: 10
  # * type: int
  refresh_interval_secs = 10

# Accepts `log` events and allows you to coerce log fields into fixed types.
[transforms.coercer]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `coercer`.
  #
  # * required
  # * type: string
  # * must be: "coercer"
  type = "coercer"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # Set to `true` to drop all fields that are not specified in the `types` table.
  # Make sure both `message` and `timestamp` are specified in the `types` table
  # as their absense will cause the original message data to be dropped along
  # with other extraneous fields.
  #
  # * optional
  # * default: false
  # * type: bool
  drop_unspecified = false
  drop_unspecified = true

  #
  # Types
  #

  [transforms.coercer.types]
    # A definition of log field type conversions. They key is the log field name
    # and the value is the type. `strptime` specifiers are supported for the
    # `timestamp` type.
    #
    # * optional
    # * no default
    # * type: string
    # * enum: "bool", "float", "int", "string", and "timestamp"
    status = "int"
    duration = "float"
    success = "bool"
    timestamp = "timestamp|%s"
    timestamp = "timestamp|%+"
    timestamp = "timestamp|%F"
    timestamp = "timestamp|%a %b %e %T %Y"

# Accepts `log` events and allows you to concat (substrings) of other fields to a new one.
[transforms.concat]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `concat`.
  #
  # * required
  # * type: string
  # * must be: "concat"
  type = "concat"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # A list of substring definitons in the format of source_field[start..end]. For
  # both start and end negative values are counted from the end of the string.
  #
  # * required
  # * type: [string]
  items = ["fist[..3]", "second[-5..]", "third[3..6]"]

  # The string that is used to join all items.
  #
  # * required
  # * default: " "
  # * type: string
  joiner = " "
  joiner = ","
  joiner = "_"
  joiner = "+"

  # The name for the new label.
  #
  # * required
  # * type: string
  target = "dest_field_name"

# Accepts `log` and `metric` events and allows you to filter events by a log field's value.
[transforms.field_filter]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `field_filter`.
  #
  # * required
  # * type: string
  # * must be: "field_filter"
  type = "field_filter"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The target log field to compare against the `value`.
  #
  # * required
  # * type: string
  field = "file"

  # If the value of the specified `field` matches this value then the event will
  # be permitted, otherwise it is dropped.
  #
  # * required
  # * type: string
  value = "/var/log/nginx.log"

# Accepts `log` events and allows you to enrich events with geolocation data from the MaxMind GeoIP2 and GeoLite2 city databases.
[transforms.geoip]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `geoip`.
  #
  # * required
  # * type: string
  # * must be: "geoip"
  type = "geoip"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # Path to the MaxMind GeoIP2 or GeoLite2 binary city database file
  # (`GeoLite2-City.mmdb`). Other databases, such as the the country database are
  # not supported.
  #
  # * required
  # * type: string
  database = "/path/to/GeoLite2-City.mmdb"

  # The field name that contains the IP address. This field should contain a
  # valid IPv4 or IPv6 address.
  #
  # * required
  # * type: string
  source = "ip_address"
  source = "x-forwarded-for"

  # The default field to insert the resulting GeoIP data into. See output for
  # more info.
  #
  # * required
  # * default: "geoip"
  # * type: string
  target = "geoip"

# Accepts `log` events and allows you to parse a log field value with Grok.
[transforms.grok_parser]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `grok_parser`.
  #
  # * required
  # * type: string
  # * must be: "grok_parser"
  type = "grok_parser"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # If `true` will drop the specified `field` after parsing.
  #
  # * required
  # * default: true
  # * type: bool
  drop_field = true
  drop_field = false

  # The log field to execute the `pattern` against. Must be a `string` value.
  #
  # * required
  # * default: "message"
  # * type: string
  field = "message"

  # The Grok pattern
  #
  # * required
  # * type: string
  pattern = "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{GREEDYDATA:message}"

  #
  # Types
  #

  [transforms.grok_parser.types]
    # A definition of log field type conversions. They key is the log field name
    # and the value is the type. `strptime` specifiers are supported for the
    # `timestamp` type.
    #
    # * optional
    # * no default
    # * type: string
    # * enum: "bool", "float", "int", "string", and "timestamp"
    status = "int"
    duration = "float"
    success = "bool"
    timestamp = "timestamp|%s"
    timestamp = "timestamp|%+"
    timestamp = "timestamp|%F"
    timestamp = "timestamp|%a %b %e %T %Y"

# Accepts `log` events and allows you to parse a log field value as JSON.
[transforms.json_parser]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `json_parser`.
  #
  # * required
  # * type: string
  # * must be: "json_parser"
  type = "json_parser"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # If the specified `field` should be dropped (removed) after parsing.
  #
  # * required
  # * default: true
  # * type: bool
  drop_field = true
  drop_field = false

  # If `true` events with invalid JSON will be dropped, otherwise the event will
  # be kept and passed through.
  #
  # * required
  # * type: bool
  drop_invalid = true

  # The log field to decode as JSON. Must be a `string` value type.
  #
  # * required
  # * default: "message"
  # * type: string
  field = "message"

  # If `target_field` is set and the log contains a field of the same name as the
  # target, it will only be overwritten if this is set to `true`.
  #
  # * optional
  # * default: false
  # * type: bool
  overwrite_target = false
  overwrite_target = true

  # If this setting is present, the parsed JSON will be inserted into the log as
  # a sub-object with this name. If a field with the same name already exists,
  # the parser will fail and produce an error.
  #
  # * optional
  # * no default
  # * type: string
  target_field = "target"

# Accepts `log` events and allows you to convert logs into one or more metrics.
[transforms.log_to_metric]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `log_to_metric`.
  #
  # * required
  # * type: string
  # * must be: "log_to_metric"
  type = "log_to_metric"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  #
  # Metrics
  #

  [[transforms.log_to_metric.metrics]]
    # The metric type.
    #
    # * required
    # * type: string
    # * enum: "counter", "gauge", "histogram", and "set"
    type = "counter"
    type = "gauge"
    type = "histogram"
    type = "set"

    # The log field to use as the metric.
    #
    # * required
    # * type: string
    field = "duration"

    # If `true` the metric will be incremented by the `field` value. If `false` the
    # metric will be incremented by 1 regardless of the `field` value.
    #
    # * required
    # * default: false
    # * type: bool
    # * relevant when type = "counter"
    increment_by_value = false
    increment_by_value = true

    # The name of the metric. Defaults to `<field>_total` for `counter` and
    # `<field>` for `gauge`.
    #
    # * required
    # * type: string
    name = "duration_total"

    [transforms.log_to_metric.metrics.tags]
      # Key/value pairs representing metric tags. Environment variables and field
      # interpolation is allowed.
      #
      # * required
      # * type: string
      host = "${HOSTNAME}"
      region = "us-east-1"
      status = "{{status}}"

# Accepts `log` events and allows you to extract data from a logfmt-formatted log field.
[transforms.logfmt_parser]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `logfmt_parser`.
  #
  # * required
  # * type: string
  # * must be: "logfmt_parser"
  type = "logfmt_parser"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # If the specified `field` should be dropped (removed) after parsing.
  #
  # * required
  # * default: true
  # * type: bool
  drop_field = true
  drop_field = false

  # The log field to parse.
  #
  # * required
  # * default: "message"
  # * type: string
  field = "message"

  #
  # Types
  #

  [transforms.logfmt_parser.types]
    # A definition of log field type conversions. They key is the log field name
    # and the value is the type. `strptime` specifiers are supported for the
    # `timestamp` type.
    #
    # * optional
    # * no default
    # * type: string
    # * enum: "bool", "float", "int", "string", and "timestamp"
    status = "int"
    duration = "float"
    success = "bool"
    timestamp = "timestamp|%s"
    timestamp = "timestamp|%+"
    timestamp = "timestamp|%F"
    timestamp = "timestamp|%a %b %e %T %Y"

# Accepts `log` events and allows you to transform events with a full embedded Lua engine.
[transforms.lua]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `lua`.
  #
  # * required
  # * type: string
  # * must be: "lua"
  type = "lua"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The inline Lua source to evaluate.
  #
  # * required
  # * type: string
  source = """
require("script") # a `script.lua` file must be in your `search_dirs`

if event["host"] == nil then
  local f = io.popen ("/bin/hostname")
  local hostname = f:read("*a") or ""
  f:close()
  hostname = string.gsub(hostname, "\n$", "")
  event["host"] = hostname
end
"""

  # A list of directories search when loading a Lua file via the `require`
  # function.
  #
  # * optional
  # * no default
  # * type: [string]
  search_dirs = ["/etc/vector/lua"]

# Accepts `log` events and allows you to parse a log field's value with a Regular Expression.
[transforms.regex_parser]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `regex_parser`.
  #
  # * required
  # * type: string
  # * must be: "regex_parser"
  type = "regex_parser"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # If the specified `field` should be dropped (removed) after parsing.
  #
  # * required
  # * default: true
  # * type: bool
  drop_field = true
  drop_field = false

  # The log field to parse.
  #
  # * required
  # * default: "message"
  # * type: string
  field = "message"

  # The Regular Expression to apply. Do not include the leading or trailing `/`.
  #
  # * required
  # * type: string
  regex = "^(?P<timestamp>[\\w\\-:\\+]+) (?P<level>\\w+) (?P<message>.*)$"

  #
  # Types
  #

  [transforms.regex_parser.types]
    # A definition of log field type conversions. They key is the log field name
    # and the value is the type. `strptime` specifiers are supported for the
    # `timestamp` type.
    #
    # * optional
    # * no default
    # * type: string
    # * enum: "bool", "float", "int", "string", and "timestamp"
    status = "int"
    duration = "float"
    success = "bool"
    timestamp = "timestamp|%s"
    timestamp = "timestamp|%+"
    timestamp = "timestamp|%F"
    timestamp = "timestamp|%a %b %e %T %Y"

# Accepts `log` events and allows you to remove one or more log fields.
[transforms.remove_fields]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `remove_fields`.
  #
  # * required
  # * type: string
  # * must be: "remove_fields"
  type = "remove_fields"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The log field names to drop.
  #
  # * required
  # * type: [string]
  fields = ["field1", "field2"]

# Accepts `metric` events and allows you to remove one or more metric tags.
[transforms.remove_tags]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `remove_tags`.
  #
  # * required
  # * type: string
  # * must be: "remove_tags"
  type = "remove_tags"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The tag names to drop.
  #
  # * required
  # * type: [string]
  tags = ["tag1", "tag2"]

# Accepts `log` events and allows you to sample events with a configurable rate.
[transforms.sampler]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `sampler`.
  #
  # * required
  # * type: string
  # * must be: "sampler"
  type = "sampler"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The rate at which events will be forwarded, expressed as 1/N. For example,
  # `rate = 10` means 1 out of every 10 events will be forwarded and the rest
  # will be dropped.
  #
  # * required
  # * type: int
  rate = 10

  # A list of regular expression patterns to exclude events from sampling. If an
  # event's `"message"` key matches _any_ of these patterns it will _not_ be
  # sampled.
  #
  # * optional
  # * no default
  # * type: [string]
  pass_list = ["[error]", "field2"]

# Accepts `log` events and allows you to split a field's value on a given separator and zip the tokens into ordered field names.
[transforms.split]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `split`.
  #
  # * required
  # * type: string
  # * must be: "split"
  type = "split"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # If `true` the `field` will be dropped after parsing.
  #
  # * required
  # * default: true
  # * type: bool
  drop_field = true
  drop_field = false

  # The field to apply the split on.
  #
  # * required
  # * default: "message"
  # * type: string
  field = "message"

  # The field names assigned to the resulting tokens, in order.
  #
  # * required
  # * type: [string]
  field_names = ["timestamp", "level", "message"]

  # The separator to split the field on. If no separator is given, it will split
  # on whitespace.
  #
  # * required
  # * default: "whitespace"
  # * type: [string]
  separator = ","

  #
  # Types
  #

  [transforms.split.types]
    # A definition of log field type conversions. They key is the log field name
    # and the value is the type. `strptime` specifiers are supported for the
    # `timestamp` type.
    #
    # * optional
    # * no default
    # * type: string
    # * enum: "bool", "float", "int", "string", and "timestamp"
    status = "int"
    duration = "float"
    success = "bool"
    timestamp = "timestamp|%s"
    timestamp = "timestamp|%+"
    timestamp = "timestamp|%F"
    timestamp = "timestamp|%a %b %e %T %Y"

# Accepts `log` events and allows you to tokenize a field's value by splitting on white space, ignoring special wrapping characters, and zip the tokens into ordered field names.
[transforms.tokenizer]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `tokenizer`.
  #
  # * required
  # * type: string
  # * must be: "tokenizer"
  type = "tokenizer"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # If `true` the `field` will be dropped after parsing.
  #
  # * required
  # * default: true
  # * type: bool
  drop_field = true
  drop_field = false

  # The log field to tokenize.
  #
  # * required
  # * default: "message"
  # * type: string
  field = "message"

  # The log field names assigned to the resulting tokens, in order.
  #
  # * required
  # * type: [string]
  field_names = ["timestamp", "level", "message"]

  #
  # Types
  #

  [transforms.tokenizer.types]
    # A definition of log field type conversions. They key is the log field name
    # and the value is the type. `strptime` specifiers are supported for the
    # `timestamp` type.
    #
    # * optional
    # * no default
    # * type: string
    # * enum: "bool", "float", "int", "string", and "timestamp"
    status = "int"
    duration = "float"
    success = "bool"
    timestamp = "timestamp|%s"
    timestamp = "timestamp|%+"
    timestamp = "timestamp|%F"
    timestamp = "timestamp|%a %b %e %T %Y"


# ------------------------------------------------------------------------------
# Sinks
# ------------------------------------------------------------------------------
# Sinks batch or stream data out of Vector.

# Batches `log` events to Amazon Web Service's CloudWatch Logs service via the `PutLogEvents` API endpoint.
[sinks.aws_cloudwatch_logs]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `aws_cloudwatch_logs`.
  #
  # * required
  # * type: string
  # * must be: "aws_cloudwatch_logs"
  type = "aws_cloudwatch_logs"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The group name of the target CloudWatch Logs stream.
  #
  # * required
  # * type: string
  group_name = "{{ file }}"
  group_name = "ec2/{{ instance_id }}"
  group_name = "group-name"

  # The AWS region of the target service. If `endpoint` is provided it will
  # override this value since the endpoint includes the region.
  #
  # * required
  # * type: string
  region = "us-east-1"

  # The stream name of the target CloudWatch Logs stream.
  #
  # * required
  # * type: string
  stream_name = "{{ instance_id }}"
  stream_name = "%Y-%m-%d"
  stream_name = "stream-name"

  # The ARN of an IAM role to assume at startup.
  #
  # * optional
  # * no default
  # * type: string
  assume_role = "arn:aws:iam::123456789098:role/my_role"

  # Dynamically create a log group if it does not already exist. This will ignore
  # `create_missing_stream` directly after creating the group and will create the
  # first stream.
  #
  # * optional
  # * default: true
  # * type: bool
  create_missing_group = true
  create_missing_group = false

  # Dynamically create a log stream if it does not already exist.
  #
  # * optional
  # * default: true
  # * type: bool
  create_missing_stream = true
  create_missing_stream = false

  # Custom endpoint for use with AWS-compatible services. Providing a value for
  # this option will make `region` moot.
  #
  # * optional
  # * no default
  # * type: string
  endpoint = "127.0.0.0:5000"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  #
  # requests
  #

  # The encoding format used to serialize the events before outputting.
  #
  # * optional
  # * no default
  # * type: string
  # * enum: "json" or "text"
  encoding = "json"
  encoding = "text"

  #
  # Batch
  #

  [sinks.aws_cloudwatch_logs.batch]
    # The maximum size of a batch before it is flushed.
    #
    # * optional
    # * default: 1049000
    # * type: int
    # * unit: bytes
    max_events = 1049000

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.aws_cloudwatch_logs.buffer]
    # The buffer's type / location. `disk` buffers are persistent and will be
    # retained between restarts.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * optional
    # * no default
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Request
  #

  [sinks.aws_cloudwatch_logs.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: int
    in_flight_limit = 5

    # The window used for the `rate_limit_num` option
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # window.
    #
    # * optional
    # * default: 5
    # * type: int
    rate_limit_num = 5

    # The maximum number of retries to make for failed requests.
    #
    # * optional
    # * default: 5
    # * type: int
    retry_attempts = 5

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 30
    # * type: int
    # * unit: seconds
    timeout_secs = 30

# Streams `metric` events to Amazon Web Service's CloudWatch Metrics service via the `PutMetricData` API endpoint.
[sinks.aws_cloudwatch_metrics]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `aws_cloudwatch_metrics`.
  #
  # * required
  # * type: string
  # * must be: "aws_cloudwatch_metrics"
  type = "aws_cloudwatch_metrics"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # A namespace that will isolate different metrics from each other.
  #
  # * required
  # * type: string
  namespace = "service"

  # The AWS region of the target service. If `endpoint` is provided it will
  # override this value since the endpoint includes the region.
  #
  # * required
  # * type: string
  region = "us-east-1"

  # Custom endpoint for use with AWS-compatible services. Providing a value for
  # this option will make `region` moot.
  #
  # * optional
  # * no default
  # * type: string
  endpoint = "127.0.0.0:5000"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

# Batches `log` events to Amazon Web Service's Kinesis Data Firehose via the `PutRecordBatch` API endpoint.
[sinks.aws_kinesis_firehose]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `aws_kinesis_firehose`.
  #
  # * required
  # * type: string
  # * must be: "aws_kinesis_firehose"
  type = "aws_kinesis_firehose"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The AWS region of the target service. If `endpoint` is provided it will
  # override this value since the endpoint includes the region.
  #
  # * required
  # * type: string
  region = "us-east-1"

  # The stream name of the target Kinesis Firehose delivery stream.
  #
  # * required
  # * type: string
  stream_name = "my-stream"

  # Custom endpoint for use with AWS-compatible services. Providing a value for
  # this option will make `region` moot.
  #
  # * optional
  # * no default
  # * type: string
  endpoint = "127.0.0.0:5000"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  #
  # requests
  #

  # The encoding format used to serialize the events before outputting.
  #
  # * optional
  # * no default
  # * type: string
  # * enum: "json" or "text"
  encoding = "json"
  encoding = "text"

  #
  # Batch
  #

  [sinks.aws_kinesis_firehose.batch]
    # The maximum size of a batch before it is flushed.
    #
    # * optional
    # * default: 500
    # * type: int
    # * unit: bytes
    max_events = 500

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.aws_kinesis_firehose.buffer]
    # The buffer's type / location. `disk` buffers are persistent and will be
    # retained between restarts.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * optional
    # * no default
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Request
  #

  [sinks.aws_kinesis_firehose.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: int
    in_flight_limit = 5

    # The window used for the `rate_limit_num` option
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # window.
    #
    # * optional
    # * default: 5
    # * type: int
    rate_limit_num = 5

    # The maximum number of retries to make for failed requests.
    #
    # * optional
    # * default: 5
    # * type: int
    retry_attempts = 5

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 30
    # * type: int
    # * unit: seconds
    timeout_secs = 30

# Batches `log` events to Amazon Web Service's Kinesis Data Stream service via the `PutRecords` API endpoint.
[sinks.aws_kinesis_streams]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `aws_kinesis_streams`.
  #
  # * required
  # * type: string
  # * must be: "aws_kinesis_streams"
  type = "aws_kinesis_streams"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The AWS region of the target service. If `endpoint` is provided it will
  # override this value since the endpoint includes the region.
  #
  # * required
  # * type: string
  region = "us-east-1"

  # The stream name of the target Kinesis Logs stream.
  #
  # * required
  # * type: string
  stream_name = "my-stream"

  # Custom endpoint for use with AWS-compatible services. Providing a value for
  # this option will make `region` moot.
  #
  # * optional
  # * no default
  # * type: string
  endpoint = "127.0.0.0:5000"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # The log field used as the Kinesis record's partition key value.
  #
  # * optional
  # * no default
  # * type: string
  partition_key_field = "user_id"

  #
  # requests
  #

  # The encoding format used to serialize the events before outputting.
  #
  # * optional
  # * no default
  # * type: string
  # * enum: "json" or "text"
  encoding = "json"
  encoding = "text"

  #
  # Batch
  #

  [sinks.aws_kinesis_streams.batch]
    # The maximum size of a batch before it is flushed.
    #
    # * optional
    # * default: 500
    # * type: int
    # * unit: bytes
    max_events = 500

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.aws_kinesis_streams.buffer]
    # The buffer's type / location. `disk` buffers are persistent and will be
    # retained between restarts.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * optional
    # * no default
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Request
  #

  [sinks.aws_kinesis_streams.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: int
    in_flight_limit = 5

    # The window used for the `rate_limit_num` option
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # window.
    #
    # * optional
    # * default: 5
    # * type: int
    rate_limit_num = 5

    # The maximum number of retries to make for failed requests.
    #
    # * optional
    # * default: 5
    # * type: int
    retry_attempts = 5

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 30
    # * type: int
    # * unit: seconds
    timeout_secs = 30

# Batches `log` events to Amazon Web Service's S3 service via the `PutObject` API endpoint.
[sinks.aws_s3]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `aws_s3`.
  #
  # * required
  # * type: string
  # * must be: "aws_s3"
  type = "aws_s3"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The S3 bucket name. Do not include a leading `s3://` or a trailing `/`.
  #
  # * required
  # * type: string
  bucket = "my-bucket"

  # The compression mechanism to use.
  #
  # * required
  # * type: string
  # * enum: "gzip" or "none"
  compression = "gzip"
  compression = "none"

  # The AWS region of the target service. If `endpoint` is provided it will
  # override this value since the endpoint includes the region.
  #
  # * required
  # * type: string
  region = "us-east-1"

  # Custom endpoint for use with AWS-compatible services. Providing a value for
  # this option will make `region` moot.
  #
  # * optional
  # * no default
  # * type: string
  endpoint = "127.0.0.0:5000"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  #
  # Object Names
  #

  # Whether or not to append a UUID v4 token to the end of the file. This ensures
  # there are no name collisions high volume use cases.
  #
  # * required
  # * default: true
  # * type: bool
  filename_append_uuid = true
  filename_append_uuid = false

  # The extension to use in the object name.
  #
  # * required
  # * default: "log"
  # * type: string
  filename_extension = "log"

  # The format of the resulting object file name. `strftime` specifiers are
  # supported.
  #
  # * required
  # * default: "%s"
  # * type: string
  filename_time_format = "%s"

  # A prefix to apply to all object key names. This should be used to partition
  # your objects, and it's important to end this value with a `/` if you want
  # this to be the root S3 "folder".
  #
  # * optional
  # * default: "date=%F/"
  # * type: string
  key_prefix = "date=%F/"
  key_prefix = "date=%F/hour=%H/"
  key_prefix = "year=%Y/month=%m/day=%d/"
  key_prefix = "application_id={{ application_id }}/date=%F/"

  #
  # requests
  #

  # The encoding format used to serialize the events before outputting.
  #
  # * optional
  # * no default
  # * type: string
  # * enum: "ndjson" or "text"
  encoding = "ndjson"
  encoding = "text"

  #
  # Batch
  #

  [sinks.aws_s3.batch]
    # The maximum size of a batch before it is flushed.
    #
    # * optional
    # * default: 10490000
    # * type: int
    # * unit: bytes
    max_size = 10490000

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 300
    # * type: int
    # * unit: seconds
    timeout_secs = 300

  #
  # Buffer
  #

  [sinks.aws_s3.buffer]
    # The buffer's type / location. `disk` buffers are persistent and will be
    # retained between restarts.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * optional
    # * no default
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Request
  #

  [sinks.aws_s3.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: int
    in_flight_limit = 5

    # The window used for the `rate_limit_num` option
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # window.
    #
    # * optional
    # * default: 5
    # * type: int
    rate_limit_num = 5

    # The maximum number of retries to make for failed requests.
    #
    # * optional
    # * default: 5
    # * type: int
    retry_attempts = 5

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 30
    # * type: int
    # * unit: seconds
    timeout_secs = 30

# Streams `log` and `metric` events to a blackhole that simply discards data, designed for testing and benchmarking purposes.
[sinks.blackhole]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `blackhole`.
  #
  # * required
  # * type: string
  # * must be: "blackhole"
  type = "blackhole"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The number of events that must be received in order to print a summary of
  # activity.
  #
  # * required
  # * type: int
  print_amount = 1000

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

# Batches `log` events to Clickhouse via the `HTTP` Interface.
[sinks.clickhouse]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `clickhouse`.
  #
  # * required
  # * type: string
  # * must be: "clickhouse"
  type = "clickhouse"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The host url of the Clickhouse server.
  #
  # * required
  # * type: string
  host = "http://localhost:8123"

  # The table that data will be inserted into.
  #
  # * required
  # * type: string
  table = "mytable"

  # The database that contains the stable that data will be inserted into.
  #
  # * optional
  # * no default
  # * type: string
  database = "mydatabase"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  #
  # requests
  #

  # The compression strategy used to compress the encoded event data before
  # outputting.
  #
  # * optional
  # * default: "gzip"
  # * type: string
  # * must be: "gzip" (if supplied)
  compression = "gzip"

  #
  # Auth
  #

  [sinks.clickhouse.auth]
    # The authentication strategy to use.
    #
    # * required
    # * type: string
    # * must be: "basic"
    strategy = "basic"

    # The basic authentication password.
    #
    # * required
    # * type: string
    # * relevant when strategy = "basic"
    password = "${PASSWORD_ENV_VAR}"
    password = "password"

    # The basic authentication user name.
    #
    # * required
    # * type: string
    # * relevant when strategy = "basic"
    user = "${USERNAME_ENV_VAR}"
    user = "username"

  #
  # Batch
  #

  [sinks.clickhouse.batch]
    # The maximum size of a batch before it is flushed.
    #
    # * optional
    # * default: 1049000
    # * type: int
    # * unit: bytes
    max_size = 1049000

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.clickhouse.buffer]
    # The buffer's type / location. `disk` buffers are persistent and will be
    # retained between restarts.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * optional
    # * no default
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Request
  #

  [sinks.clickhouse.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: int
    in_flight_limit = 5

    # The window used for the `rate_limit_num` option
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # window.
    #
    # * optional
    # * default: 5
    # * type: int
    rate_limit_num = 5

    # The maximum number of retries to make for failed requests.
    #
    # * optional
    # * default: 9223372036854775807
    # * type: int
    retry_attempts = 9223372036854775807

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 30
    # * type: int
    # * unit: seconds
    timeout_secs = 30

  #
  # Tls
  #

  [sinks.clickhouse.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509).
    #
    # * optional
    # * no default
    # * type: string
    ca_path = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this connection, in DER
    # or PEM format (X.509) or PKCS#12. If this is set and is not a PKCS#12
    # archive, `key_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    crt_path = "/path/to/host_certificate.crt"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_pass` above is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "PassWord1"

    # Absolute path to a certificate key file used to identify this connection, in
    # DER or PEM format (PKCS#8). If this is set, `crt_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    key_path = "/path/to/host_certificate.key"

    # If `true` (the default), Vector will validate the TLS certificate of the
    # remote host. Do NOT set this to `false` unless you understand the risks of
    # not verifying the remote certificate.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_certificate = true
    verify_certificate = false

    # If `true` (the default), Vector will validate the configured remote host name
    # against the remote host's TLS certificate. Do NOT set this to `false` unless
    # you understand the risks of not verifying the remote hostname.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_hostname = true
    verify_hostname = false

# Streams `log` and `metric` events to standard output streams, such as `STDOUT` and `STDERR`.
[sinks.console]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `console`.
  #
  # * required
  # * type: string
  # * must be: "console"
  type = "console"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The standard stream to write to.
  #
  # * required
  # * default: "stdout"
  # * type: string
  # * enum: "stdout" or "stderr"
  target = "stdout"
  target = "stderr"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  #
  # requests
  #

  # The encoding format used to serialize the events before outputting.
  #
  # * optional
  # * no default
  # * type: string
  # * enum: "json" or "text"
  encoding = "json"
  encoding = "text"

# Batches `metric` events to Datadog's metrics service using HTTP API.
[sinks.datadog_metrics]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `datadog_metrics`.
  #
  # * required
  # * type: string
  # * must be: "datadog_metrics"
  type = "datadog_metrics"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # Datadog API key
  #
  # * required
  # * type: string
  api_key = "3111111111111111aaaaaaaaaaaaaaaa"

  # A prefix that will be added to all metric names.
  #
  # * required
  # * type: string
  namespace = "service"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # Datadog endpoint to send metrics to.
  #
  # * optional
  # * default: "https://api.datadoghq.com"
  # * type: string
  host = "https://api.datadoghq.com"
  host = "https://api.datadoghq.eu"

  #
  # Batch
  #

  [sinks.datadog_metrics.batch]
    # The maximum size of a batch before it is flushed.
    #
    # * optional
    # * default: 20
    # * type: int
    # * unit: bytes
    max_events = 20

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    timeout_secs = 1

  #
  # Request
  #

  [sinks.datadog_metrics.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: int
    in_flight_limit = 5

    # The window used for the `rate_limit_num` option
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # window.
    #
    # * optional
    # * default: 5
    # * type: int
    rate_limit_num = 5

    # The maximum number of retries to make for failed requests.
    #
    # * optional
    # * default: 5
    # * type: int
    retry_attempts = 5

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 60
    # * type: int
    # * unit: seconds
    timeout_secs = 60

# Batches `log` events to Elasticsearch via the `_bulk` API endpoint.
[sinks.elasticsearch]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `elasticsearch`.
  #
  # * required
  # * type: string
  # * must be: "elasticsearch"
  type = "elasticsearch"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The `doc_type` for your index data. This is only relevant for Elasticsearch
  # <= 6.X. If you are using >= 7.0 you do not need to set this option since
  # Elasticsearch has removed it.
  #
  # * required
  # * default: "_doc"
  # * type: string
  doc_type = "_doc"

  # Index name to write events to.
  #
  # * required
  # * default: "vector-%F"
  # * type: string
  index = "application-{{ application_id }}-%Y-%m-%d"
  index = "vector-%Y-%m-%d"

  # Custom endpoint for use with AWS-compatible services. Providing a value for
  # this option will make `region` moot.
  #
  # * optional
  # * no default
  # * type: string
  endpoint = "127.0.0.0:5000"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # The host of your Elasticsearch cluster. This should be the full URL as shown
  # in the example. This is required if the `provider` is not `"aws"`
  #
  # * optional
  # * no default
  # * type: string
  host = "http://10.24.32.122:9000"

  # The AWS region of the target service. If `endpoint` is provided it will
  # override this value since the endpoint includes the region.
  #
  # * optional
  # * no default
  # * type: string
  region = "us-east-1"

  #
  # Auth
  #

  [sinks.elasticsearch.auth]
    # The authentication strategy to use.
    #
    # * required
    # * type: string
    # * enum: "aws" or "basic"
    strategy = "aws"
    strategy = "basic"

    # The basic authentication password.
    #
    # * required
    # * type: string
    # * relevant when strategy = "basic"
    password = "${PASSWORD_ENV_VAR}"
    password = "password"

    # The basic authentication user name.
    #
    # * required
    # * type: string
    # * relevant when strategy = "basic"
    user = "${USERNAME_ENV_VAR}"
    user = "username"

  #
  # Batch
  #

  [sinks.elasticsearch.batch]
    # The maximum size of a batch before it is flushed.
    #
    # * optional
    # * default: 10490000
    # * type: int
    # * unit: bytes
    max_size = 10490000

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.elasticsearch.buffer]
    # The buffer's type / location. `disk` buffers are persistent and will be
    # retained between restarts.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * optional
    # * no default
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Headers
  #

  [sinks.elasticsearch.headers]
    # A custom header to be added to each outgoing Elasticsearch request.
    #
    # * required
    # * type: string
    Authorization = "${TOKEN_ENV_VAR}"
    X-Powered-By = "Vector"

  #
  # Query
  #

  [sinks.elasticsearch.query]
    # A custom parameter to be added to each Elasticsearch request.
    #
    # * required
    # * type: string
    X-Powered-By = "Vector"

  #
  # Request
  #

  [sinks.elasticsearch.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: int
    in_flight_limit = 5

    # The window used for the `rate_limit_num` option
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # window.
    #
    # * optional
    # * default: 5
    # * type: int
    rate_limit_num = 5

    # The maximum number of retries to make for failed requests.
    #
    # * optional
    # * default: 5
    # * type: int
    retry_attempts = 5

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 60
    # * type: int
    # * unit: seconds
    timeout_secs = 60

  #
  # Tls
  #

  [sinks.elasticsearch.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509).
    #
    # * optional
    # * no default
    # * type: string
    ca_path = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this connection, in DER
    # or PEM format (X.509) or PKCS#12. If this is set and is not a PKCS#12
    # archive, `key_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    crt_path = "/path/to/host_certificate.crt"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_pass` above is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "PassWord1"

    # Absolute path to a certificate key file used to identify this connection, in
    # DER or PEM format (PKCS#8). If this is set, `crt_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    key_path = "/path/to/host_certificate.key"

    # If `true` (the default), Vector will validate the TLS certificate of the
    # remote host. Do NOT set this to `false` unless you understand the risks of
    # not verifying the remote certificate.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_certificate = true
    verify_certificate = false

    # If `true` (the default), Vector will validate the configured remote host name
    # against the remote host's TLS certificate. Do NOT set this to `false` unless
    # you understand the risks of not verifying the remote hostname.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_hostname = true
    verify_hostname = false

# Streams `log` events to a file.
[sinks.file]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `file`.
  #
  # * required
  # * type: string
  # * must be: "file"
  type = "file"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # File name to write events to.
  #
  # * required
  # * type: string
  path = "vector-%Y-%m-%d.log"
  path = "application-{{ application_id }}-%Y-%m-%d.log"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # The amount of time a file can be idle  and stay open. After not receiving any
  # events for this timeout, the file will be flushed and closed.
  #
  # * optional
  # * default: "30"
  # * type: int
  idle_timeout_secs = "30"

  #
  # requests
  #

  # The encoding format used to serialize the events before outputting.
  #
  # * optional
  # * no default
  # * type: string
  # * enum: "ndjson" or "text"
  encoding = "ndjson"
  encoding = "text"

# Batches `log` events to Google Cloud Platform's Pubsub service via the REST Interface.
[sinks.gcp_pubsub]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `gcp_pubsub`.
  #
  # * required
  # * type: string
  # * must be: "gcp_pubsub"
  type = "gcp_pubsub"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The project name to which to publish logs.
  #
  # * required
  # * type: string
  project = "vector-123456"

  # The topic within the project to which to publish logs.
  #
  # * required
  # * type: string
  topic = "this-is-a-topic"

  # A Google Cloud API key used to authenticate access the pubsub project and
  # topic. Either this or `credentials_path` must be set.
  #
  # * optional
  # * no default
  # * type: string

  # The filename for a Google Cloud service account credentials JSON file used to
  # authenticate access to the pubsub project and topic. If this is unset, Vector
  # checks the `$GOOGLE_APPLICATION_CREDENTIALS` environment variable for a
  # filename. Either this or `api_key` must be set.
  #
  # * optional
  # * no default
  # * type: string

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  #
  # Batch
  #

  [sinks.gcp_pubsub.batch]
    # The maximum size of a batch before it is flushed.
    #
    # * optional
    # * default: 10485760
    # * type: int
    # * unit: bytes
    max_size = 10485760

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.gcp_pubsub.buffer]
    # The buffer's type / location. `disk` buffers are persistent and will be
    # retained between restarts.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * optional
    # * no default
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Request
  #

  [sinks.gcp_pubsub.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: int
    in_flight_limit = 5

    # The window used for the `rate_limit_num` option
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # window.
    #
    # * optional
    # * default: 100
    # * type: int
    rate_limit_num = 100

    # The maximum number of retries to make for failed requests.
    #
    # * optional
    # * default: 9223372036854775807
    # * type: int
    retry_attempts = 9223372036854775807

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 60
    # * type: int
    # * unit: seconds
    timeout_secs = 60

  #
  # Tls
  #

  [sinks.gcp_pubsub.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509).
    #
    # * optional
    # * no default
    # * type: string
    ca_path = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this connection, in DER
    # or PEM format (X.509) or PKCS#12. If this is set and is not a PKCS#12
    # archive, `key_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    crt_path = "/path/to/host_certificate.crt"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_pass` above is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "PassWord1"

    # Absolute path to a certificate key file used to identify this connection, in
    # DER or PEM format (PKCS#8). If this is set, `crt_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    key_path = "/path/to/host_certificate.key"

    # If `true` (the default), Vector will validate the TLS certificate of the
    # remote host. Do NOT set this to `false` unless you understand the risks of
    # not verifying the remote certificate.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_certificate = true
    verify_certificate = false

    # If `true` (the default), Vector will validate the configured remote host name
    # against the remote host's TLS certificate. Do NOT set this to `false` unless
    # you understand the risks of not verifying the remote hostname.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_hostname = true
    verify_hostname = false

# Batches `log` events to Google Cloud Platform's Stackdriver Logging service via the REST Interface.
[sinks.gcp_stackdriver_logging]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `gcp_stackdriver_logging`.
  #
  # * required
  # * type: string
  # * must be: "gcp_stackdriver_logging"
  type = "gcp_stackdriver_logging"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The filename for a Google Cloud service account credentials JSON file used to
  # authenticate access to the stackdriver logging API. If this is unset, Vector
  # checks the `$GOOGLE_APPLICATION_CREDENTIALS` environment variable for a
  # filename.
  #
  # * required
  # * type: string
  credentials_path = "/path/to/credentials.json"

  # The log ID to which to publish logs. This is a name you create to identify
  # this log stream.
  #
  # * required
  # * type: string
  log_id = "vector-logs"

  # The project ID to which to publish logs. See the Google Cloud Platform
  # project management documentation for more details.
  #
  # Exactly one of `billing_account_id`, `folder_id`, `organization_id`, or
  # `project_id` must be set.
  #
  # * required
  # * type: string
  project_id = "vector-123456"

  # The billing account ID to which to publish logs.
  #
  # Exactly one of `billing_account_id`, `folder_id`, `organization_id`, or
  # `project_id` must be set.
  #
  # * optional
  # * no default
  # * type: string
  billing_account_id = "012345-6789AB-CDEF01"

  # The folder ID to which to publish logs.
  # See the Google Cloud Platform folder documentation for more details.
  #
  # Exactly one of `billing_account_id`, `folder_id`, `organization_id`, or
  # `project_id` must be set.
  #
  # * optional
  # * no default
  # * type: string
  folder_id = "My Folder"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # The organization ID to which to publish logs. This would be the identifier
  # assigned to your organization on Google Cloud Platform.
  #
  # Exactly one of `billing_account_id`, `folder_id`, `organization_id`, or
  # `project_id` must be set.
  #
  # * optional
  # * no default
  # * type: string
  organization_id = "622418129737"

  #
  # Batch
  #

  [sinks.gcp_stackdriver_logging.batch]
    # The maximum size of a batch before it is flushed.
    #
    # * optional
    # * default: 5242880
    # * type: int
    # * unit: bytes
    max_size = 5242880

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.gcp_stackdriver_logging.buffer]
    # The buffer's type / location. `disk` buffers are persistent and will be
    # retained between restarts.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * optional
    # * no default
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Request
  #

  [sinks.gcp_stackdriver_logging.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: int
    in_flight_limit = 5

    # The window used for the `rate_limit_num` option
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # window.
    #
    # * optional
    # * default: 1000
    # * type: int
    rate_limit_num = 1000

    # The maximum number of retries to make for failed requests.
    #
    # * optional
    # * default: 9223372036854775807
    # * type: int
    retry_attempts = 9223372036854775807

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 60
    # * type: int
    # * unit: seconds
    timeout_secs = 60

  #
  # Resource
  #

  [sinks.gcp_stackdriver_logging.resource]
    # The monitored resource type. For example, the type of a Compute Engine VM
    # instance is gce_instance.
    #
    # See the Google Cloud Platform monitored resource documentation for more
    # details.
    #
    # * optional
    # * no default
    # * type: string
    type = "global"
    type = "gce_instance"

    # Values for all of the labels listed in the associated monitored resource
    # descriptor.
    #
    # For example, Compute Engine VM instances use the labels `projectId`,
    # `instanceId`, and `zone`.
    #
    # * optional
    # * no default
    # * type: string
    projectId = "vector-123456"
    zone = "Twilight"

  #
  # Tls
  #

  [sinks.gcp_stackdriver_logging.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509).
    #
    # * optional
    # * no default
    # * type: string
    ca_path = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this connection, in DER
    # or PEM format (X.509) or PKCS#12. If this is set and is not a PKCS#12
    # archive, `key_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    crt_path = "/path/to/host_certificate.crt"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_pass` above is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "PassWord1"

    # Absolute path to a certificate key file used to identify this connection, in
    # DER or PEM format (PKCS#8). If this is set, `crt_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    key_path = "/path/to/host_certificate.key"

    # If `true` (the default), Vector will validate the TLS certificate of the
    # remote host. Do NOT set this to `false` unless you understand the risks of
    # not verifying the remote certificate.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_certificate = true
    verify_certificate = false

    # If `true` (the default), Vector will validate the configured remote host name
    # against the remote host's TLS certificate. Do NOT set this to `false` unless
    # you understand the risks of not verifying the remote hostname.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_hostname = true
    verify_hostname = false

# Batches `log` events to a generic HTTP endpoint.
[sinks.http]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `http`.
  #
  # * required
  # * type: string
  # * must be: "http"
  type = "http"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The full URI to make HTTP requests to. This should include the protocol and
  # host, but can also include the port, path, and any other valid part of a URI.
  #
  # * required
  # * type: string
  uri = "https://10.22.212.22:9000/endpoint"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # A URI that Vector can request in order to determine the service health.
  #
  # * optional
  # * no default
  # * type: string
  healthcheck_uri = "https://10.22.212.22:9000/_health"

  #
  # requests
  #

  # The encoding format used to serialize the events before outputting.
  #
  # * optional
  # * no default
  # * type: string
  # * enum: "ndjson", "json", and "text"
  encoding = "ndjson"
  encoding = "json"
  encoding = "text"

  #
  # Auth
  #

  [sinks.http.auth]
    # The authentication strategy to use.
    #
    # * required
    # * type: string
    # * must be: "basic"
    strategy = "basic"

    # The basic authentication password.
    #
    # * required
    # * type: string
    # * relevant when strategy = "basic"
    password = "${PASSWORD_ENV_VAR}"
    password = "password"

    # The basic authentication user name.
    #
    # * required
    # * type: string
    # * relevant when strategy = "basic"
    user = "${USERNAME_ENV_VAR}"
    user = "username"

  #
  # Batch
  #

  [sinks.http.batch]
    # The maximum size of a batch before it is flushed.
    #
    # * optional
    # * default: 1049000
    # * type: int
    # * unit: bytes
    max_size = 1049000

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.http.buffer]
    # The buffer's type / location. `disk` buffers are persistent and will be
    # retained between restarts.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * optional
    # * no default
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Headers
  #

  [sinks.http.headers]
    # A custom header to be added to each outgoing HTTP request.
    #
    # * required
    # * type: string
    Authorization = "${TOKEN_ENV_VAR}"
    X-Powered-By = "Vector"

  #
  # Request
  #

  [sinks.http.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 10
    # * type: int
    in_flight_limit = 10

    # The window used for the `rate_limit_num` option
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # window.
    #
    # * optional
    # * default: 10
    # * type: int
    rate_limit_num = 10

    # The maximum number of retries to make for failed requests.
    #
    # * optional
    # * default: 10
    # * type: int
    retry_attempts = 10

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 30
    # * type: int
    # * unit: seconds
    timeout_secs = 30

  #
  # Tls
  #

  [sinks.http.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509).
    #
    # * optional
    # * no default
    # * type: string
    ca_path = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this connection, in DER
    # or PEM format (X.509) or PKCS#12. If this is set and is not a PKCS#12
    # archive, `key_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    crt_path = "/path/to/host_certificate.crt"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_pass` above is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "PassWord1"

    # Absolute path to a certificate key file used to identify this connection, in
    # DER or PEM format (PKCS#8). If this is set, `crt_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    key_path = "/path/to/host_certificate.key"

    # If `true` (the default), Vector will validate the TLS certificate of the
    # remote host. Do NOT set this to `false` unless you understand the risks of
    # not verifying the remote certificate.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_certificate = true
    verify_certificate = false

    # If `true` (the default), Vector will validate the configured remote host name
    # against the remote host's TLS certificate. Do NOT set this to `false` unless
    # you understand the risks of not verifying the remote hostname.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_hostname = true
    verify_hostname = false

# Streams `log` events to Apache Kafka via the Kafka protocol.
[sinks.kafka]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `kafka`.
  #
  # * required
  # * type: string
  # * must be: "kafka"
  type = "kafka"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # A comma delimited list of host and port pairs that the Kafka client should
  # contact to bootstrap its cluster metadata.
  #
  # * required
  # * type: string
  bootstrap_servers = "10.14.22.123:9092,10.14.23.332:9092"

  # The log field name to use for the topic key. If unspecified, the key will be
  # randomly generated. If the field does not exist on the log, a blank value
  # will be used.
  #
  # * required
  # * type: string
  key_field = "user_id"

  # The Kafka topic name to write events to.
  #
  # * required
  # * type: string
  topic = "topic-1234"

  # Custom endpoint for use with AWS-compatible services. Providing a value for
  # this option will make `region` moot.
  #
  # * optional
  # * no default
  # * type: string
  endpoint = "127.0.0.0:5000"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # The AWS region of the target service. If `endpoint` is provided it will
  # override this value since the endpoint includes the region.
  #
  # * optional
  # * no default
  # * type: string
  region = "us-east-1"

  #
  # requests
  #

  # The encoding format used to serialize the events before outputting.
  #
  # * optional
  # * no default
  # * type: string
  # * enum: "json" or "text"
  encoding = "json"
  encoding = "text"

  #
  # Buffer
  #

  [sinks.kafka.buffer]
    # The buffer's type / location. `disk` buffers are persistent and will be
    # retained between restarts.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * optional
    # * no default
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Tls
  #

  [sinks.kafka.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509).
    #
    # * optional
    # * no default
    # * type: string
    ca_path = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this connection, in DER
    # or PEM format (X.509) or PKCS#12. If this is set and is not a PKCS#12
    # archive, `key_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    crt_path = "/path/to/host_certificate.crt"

    # Enable TLS during connections to the remote.
    #
    # * optional
    # * default: false
    # * type: bool
    enabled = false
    enabled = true

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_pass` above is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "PassWord1"

    # Absolute path to a certificate key file used to identify this connection, in
    # DER or PEM format (PKCS#8). If this is set, `crt_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    key_path = "/path/to/host_certificate.key"

# Batches `log` events to New Relic's log service via their log API.
[sinks.new_relic_logs]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `new_relic_logs`.
  #
  # * required
  # * type: string
  # * must be: "new_relic_logs"
  type = "new_relic_logs"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # Your New Relic insert key (if applicable).
  #
  # * optional
  # * no default
  # * type: string
  insert_key = "xxxx"
  insert_key = "${INSERT_KEY_ENV_VAR}"

  # Your New Relic license key (if applicable).
  #
  # * optional
  # * no default
  # * type: string
  license_key = "xxxx"
  license_key = "${LICENSE_KEY_ENV_VAR}"

  # The API region to send logs to.
  #
  # * optional
  # * default: "us"
  # * type: string
  # * enum: "us" or "eu"
  region = "us"
  region = "eu"

  #
  # Batch
  #

  [sinks.new_relic_logs.batch]
    # The maximum size of a batch before it is flushed.
    #
    # * optional
    # * default: 524000
    # * type: int
    # * unit: bytes
    max_size = 524000

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.new_relic_logs.buffer]
    # The buffer's type / location. `disk` buffers are persistent and will be
    # retained between restarts.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * optional
    # * no default
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Request
  #

  [sinks.new_relic_logs.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 100
    # * type: int
    in_flight_limit = 100

    # The window used for the `rate_limit_num` option
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # window.
    #
    # * optional
    # * default: 100
    # * type: int
    rate_limit_num = 100

    # The maximum number of retries to make for failed requests.
    #
    # * optional
    # * default: 10
    # * type: int
    retry_attempts = 10

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 30
    # * type: int
    # * unit: seconds
    timeout_secs = 30

# Exposes `metric` events to Prometheus metrics service.
[sinks.prometheus]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `prometheus`.
  #
  # * required
  # * type: string
  # * must be: "prometheus"
  type = "prometheus"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The address to expose for scraping.
  #
  # * required
  # * type: string
  address = "0.0.0.0:9598"

  # Default buckets to use for aggregating distribution metrics into histograms.
  #
  # * required
  # * default: [0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0]
  # * type: [float]
  # * unit: seconds
  buckets = [0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0]

  # Time interval between set values are reset.
  #
  # * required
  # * default: 60
  # * type: int
  # * unit: seconds
  flush_period_secs = 60

  # A prefix that will be added to all metric names.
  # It should follow Prometheus naming conventions.
  #
  # * required
  # * type: string
  namespace = "service"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

# Batches `log` events to Sematext via the Elasticsearch API.
[sinks.sematext]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `sematext`.
  #
  # * required
  # * type: string
  # * must be: "sematext"
  type = "sematext"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The cloud destination to send logs to.
  #
  # * required
  # * type: string
  cloud = "north_america"
  cloud = "europe"

  # The token that will be used to write to Sematext.
  #
  # * required
  # * type: string
  token = "some-sematext-token"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  #
  # Batch
  #

  [sinks.sematext.batch]
    # The maximum size of a batch before it is flushed.
    #
    # * optional
    # * default: 10490000
    # * type: int
    # * unit: bytes
    max_size = 10490000

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.sematext.buffer]
    # The buffer's type / location. `disk` buffers are persistent and will be
    # retained between restarts.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * optional
    # * no default
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Request
  #

  [sinks.sematext.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: int
    in_flight_limit = 5

    # The window used for the `rate_limit_num` option
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # window.
    #
    # * optional
    # * default: 5
    # * type: int
    rate_limit_num = 5

    # The maximum number of retries to make for failed requests.
    #
    # * optional
    # * default: 5
    # * type: int
    retry_attempts = 5

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 60
    # * type: int
    # * unit: seconds
    timeout_secs = 60

# Streams `log` events to a socket, such as a TCP, UDP, or Unix socket.
[sinks.socket]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `socket`.
  #
  # * required
  # * type: string
  # * must be: "socket"
  type = "socket"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The address to connect to. The address _must_ include a port.
  #
  # * required
  # * type: string
  address = "92.12.333.224:5000"

  # The type of socket to use. Currently only `tcp` is valid.
  #
  # * required
  # * type: string
  # * must be: "tcp"
  mode = "tcp"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  #
  # requests
  #

  # The encoding format used to serialize the events before outputting.
  #
  # * optional
  # * no default
  # * type: string
  # * enum: "json" or "text"
  encoding = "json"
  encoding = "text"

  #
  # Buffer
  #

  [sinks.socket.buffer]
    # The buffer's type / location. `disk` buffers are persistent and will be
    # retained between restarts.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * optional
    # * no default
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Tls
  #

  [sinks.socket.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509).
    #
    # * optional
    # * no default
    # * type: string
    ca_path = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this connection, in DER
    # or PEM format (X.509) or PKCS#12. If this is set and is not a PKCS#12
    # archive, `key_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    crt_path = "/path/to/host_certificate.crt"

    # Enable TLS during connections to the remote.
    #
    # * optional
    # * default: false
    # * type: bool
    enabled = false
    enabled = true

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_pass` above is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "PassWord1"

    # Absolute path to a certificate key file used to identify this connection, in
    # DER or PEM format (PKCS#8). If this is set, `crt_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    key_path = "/path/to/host_certificate.key"

    # If `true` (the default), Vector will validate the TLS certificate of the
    # remote host. Do NOT set this to `false` unless you understand the risks of
    # not verifying the remote certificate.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_certificate = true
    verify_certificate = false

    # If `true` (the default), Vector will validate the configured remote host name
    # against the remote host's TLS certificate. Do NOT set this to `false` unless
    # you understand the risks of not verifying the remote hostname.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_hostname = true
    verify_hostname = false

# Batches `log` events to a Splunk's HTTP Event Collector.
[sinks.splunk_hec]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `splunk_hec`.
  #
  # * required
  # * type: string
  # * must be: "splunk_hec"
  type = "splunk_hec"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # Your Splunk HEC host.
  #
  # * required
  # * type: string
  host = "my-splunk-host.com"

  # Your Splunk HEC token.
  #
  # * required
  # * type: string
  token = "${TOKEN_ENV_VAR}"
  token = "A94A8FE5CCB19BA61C4C08"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # Fields to be added to Splunk index.
  #
  # * optional
  # * no default
  # * type: [string]
  # * relevant when encoding = "json"
  indexed_fields = ["field1", "field2"]

  #
  # requests
  #

  # The encoding format used to serialize the events before outputting.
  #
  # * optional
  # * no default
  # * type: string
  # * enum: "ndjson" or "text"
  encoding = "ndjson"
  encoding = "text"

  #
  # Batch
  #

  [sinks.splunk_hec.batch]
    # The maximum size of a batch before it is flushed.
    #
    # * optional
    # * default: 1049000
    # * type: int
    # * unit: bytes
    max_size = 1049000

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.splunk_hec.buffer]
    # The buffer's type / location. `disk` buffers are persistent and will be
    # retained between restarts.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * optional
    # * no default
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Request
  #

  [sinks.splunk_hec.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 10
    # * type: int
    in_flight_limit = 10

    # The window used for the `rate_limit_num` option
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # window.
    #
    # * optional
    # * default: 10
    # * type: int
    rate_limit_num = 10

    # The maximum number of retries to make for failed requests.
    #
    # * optional
    # * default: 5
    # * type: int
    retry_attempts = 5

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: int
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: int
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 60
    # * type: int
    # * unit: seconds
    timeout_secs = 60

  #
  # Tls
  #

  [sinks.splunk_hec.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509).
    #
    # * optional
    # * no default
    # * type: string
    ca_path = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this connection, in DER
    # or PEM format (X.509) or PKCS#12. If this is set and is not a PKCS#12
    # archive, `key_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    crt_path = "/path/to/host_certificate.crt"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_pass` above is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "PassWord1"

    # Absolute path to a certificate key file used to identify this connection, in
    # DER or PEM format (PKCS#8). If this is set, `crt_path` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    key_path = "/path/to/host_certificate.key"

    # If `true` (the default), Vector will validate the TLS certificate of the
    # remote host. Do NOT set this to `false` unless you understand the risks of
    # not verifying the remote certificate.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_certificate = true
    verify_certificate = false

    # If `true` (the default), Vector will validate the configured remote host name
    # against the remote host's TLS certificate. Do NOT set this to `false` unless
    # you understand the risks of not verifying the remote hostname.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_hostname = true
    verify_hostname = false

# Streams `metric` events to StatsD metrics service.
[sinks.statsd]
  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `statsd`.
  #
  # * required
  # * type: string
  # * must be: "statsd"
  type = "statsd"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # A prefix that will be added to all metric names.
  #
  # * required
  # * type: string
  namespace = "service"

  # The UDP socket address to send stats to.
  #
  # * optional
  # * default: "127.0.0.1:8125"
  # * type: string
  address = "127.0.0.1:8125"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

# Streams `log` events to another downstream `vector` source.
[sinks.vector]
  #
  # General
  #

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `vector`.
  #
  # * required
  # * type: string
  # * must be: "vector"
  type = "vector"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-id"]

  # The downstream Vector address to connect to. The address _must_ include a
  # port.
  #
  # * required
  # * type: string
  address = "92.12.333.224:5000"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  #
  # Buffer
  #

  [sinks.vector.buffer]
    # The buffer's type / location. `disk` buffers are persistent and will be
    # retained between restarts.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: int
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * optional
    # * no default
    # * type: int
    # * unit: bytes
    # * relevant when type = "disk"
    max_size = 104900000

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"
