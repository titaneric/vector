[transforms.tokenizer]
title = "Tokenizer"
allow_you_to_description = """\
tokenize a field's value by splitting on white space, ignoring special \
wrapping characters, and zip the tokens into ordered field names\
"""
common = true
function_category = "parse"
input_types = ["log"]
output_types = ["log"]
types_coercion = true

[transforms.tokenizer.options.field]
type = "string"
common = true
default = "message"
null = false
description = "The log field to tokenize."

[transforms.tokenizer.options.field_names]
type = "[string]"
common = true
examples = [["timestamp", "level", "message"]]
null = false
description = "The log field names assigned to the resulting tokens, in order."

[transforms.tokenizer.options.drop_field]
type = "bool"
common = true
default = true
null = false
description = "If `true` the `field` will be dropped after parsing."
