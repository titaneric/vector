[sinks.kafka]
buffer = true
delivery_guarantee = "at_least_once"
egress_method = "streaming"
healthcheck = true
input_types = ["log"]
service_provider = "Confluent"
write_to_description = "[Apache Kafka][url.kafka] via the [Kafka protocol][url.kafka_protocol]"

[sinks.kafka.options.bootstrap_servers]
type = "string"
examples = ["10.14.22.123:9092,10.14.23.332:9092"]
null = false
description = """\
A comma-separated list of host and port pairs that are the addresses of the \
Kafka brokers in a \"bootstrap\" Kafka cluster that a Kafka client connects \
to initially to bootstrap itself\
"""

[sinks.kafka.options.encoding]
type = "string"
enum = ["json", "text"]
null = true
description = """\
The encoding format used to serialize the events before flushing. The default \
is dynamic based on if the event is structured or not.\
"""

[sinks.kafka.options.key_field]
type = "string"
examples = ["user_id"]
null = false
description = """\
The log field name to use for the topic key. If unspecified, the key will be \
randomly generated. If the field does not exist on the log, a blank value \
will be used.\
"""

[sinks.kafka.options.topic]
type = "string"
examples = ["topic-1234"]
null = false
description = "The Kafka topic name to write events to."