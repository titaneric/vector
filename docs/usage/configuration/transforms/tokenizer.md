---
description: tokenize a field's value by splitting on white space and zipping the tokens with ordered field names
---

<!---
!!!WARNING!!!!

This file is autogenerated! Please do not manually edit this file.
Instead, please modify the contents of `dist/config/schema.toml`.
-->

# tokenizer transform

![](../../../.gitbook/assets/tokenizer-transform.svg)


The `tokenizer` transforms accepts [`log`][log_event] events and allows you to tokenize a field's value by splitting on white space and zipping the tokens with ordered field names.

## Example

{% code-tabs %}
{% code-tabs-item title="vector.toml (examples)" %}
```coffeescript
[transforms.my_tokenizer_transform]
  # REQUIRED - General
  type = "tokenizer"
  inputs = ["my-source-id"]

  # OPTIONAL - General
  drop_field = true # default
  field = "message" # default
  field_names = ["timestamp", "level", "message"] # no default
```
{% endcode-tabs-item %}
{% code-tabs-item title="vector.toml (schema)" %}
```coffeescript
[transforms.<transform-id>]
  # REQUIRED - General
  type = "<string>"
  inputs = "<string>"

  # OPTIONAL - General
  drop_field = <bool>
  field = "<string>"
  field_names = ["<string>", ...]
```
{% endcode-tabs-item %}
{% endcode-tabs %}

## Options

| Key  | Type  | Description |
| :--- | :---: | :---------- |
| **REQUIRED** - General | | |
| `inputs` | `string` | A list of upstream [source][sources] or [transform][transforms] IDs. See [Config Composition][config_composition] for more info.<br />`required` `example: ["my-source-id"]` |
| **OPTIONAL** - General | | |
| `drop_field` | `bool` | If `true` the `field` will be dropped after parsing.<br />`default: true` |
| `field` | `string` | The field to tokenize. See [Example](#example) for more info.<br />`default: "message"` |
| `field_names` | `[string]` | The field names assigned to the resulting tokens, in order. See [Example](#example) for more info.<br />`no default` `example: (see above)` |

## Input

The `tokenizer` accepts [`log`][log_event] events.

## Output

The `tokenizer` outputs [`log`][log_event] events.



## How It Works

### Example

The specified `field`'s value is tokenized by splitting on it's white space.

For example, take this config:

{% code-tabs %}
{% code-tabs-item title="vector.toml" %}
```coffeescript
[transforms.<transform-id>]
type = "tokenizer"
field = "message"
fields = ["timestamp", "level", "message"]
```
{% endcode-tabs-item %}
{% endcode-tabs %}

And this event:

```json
{
  "message": "2019-05-22T23:22:55.256231Z [INFO] "Hello world""
}
```

This transform will produce the following tokens:

```
["2019-05-22T23:22:55.256231Z", "INFO", "Hello world"]
```

You'll notice that the `[`, `]`, and `"` characters are not included, they are [special characters](#special-characters). To proceed, these tokesn will be zipped with the provided `field_names` and merged into the event:

```json
{
  "timestamp": "2019-05-22T23:22:55.256231Z",
  "level": "INFO",
  "message": "Hello world"
}
```

### Special Characters

In order to extract raw values without noise we must treat certain characters as special:

* `"..."` - Is used tp wrap phrases. Spaces are preserved, but the wrapping quotes will be discarded.
* `[...]` - Is used to wrap phrases. Spaces are preserved, but the wrapping brackers will be discarded.
* `\` - Can be used to escape the above characters, making them literal.

## Troubleshooting

The best place to start with troubleshooting is to check the
[Vector logs][monitoring_logs]. This is typically located at
`/var/log/vector.log`, then proceed to follow the
[Troubleshooting Guide][troubleshooting].

### Getting help

If the [Troubleshooting Guide][troubleshooting] does not resolve your
issue, please:

1. Check for any [open transform issues](https://github.com/timberio/vector/issues?q=is%3Aopen+is%3Aissue+label%3A%22Transform%3A+tokenizer%22).
2. [Search the forum][search_forum] for any similar issues.
2. Reach out to the [community][community] for help.
### Alternatives

Finally, consider the following alternatives:

* [`grok_parser` transform][grok_parser_transform]
* [`lua` transform][lua_transform]
* [`regex_parser` transform][regex_parser_transform]

## Resources

* [**Issues**](https://github.com/timberio/vector/issues?q=is%3Aopen+is%3Aissue+label%3A%22Transform%3A+tokenizer%22) - [enhancements](https://github.com/timberio/vector/issues?q=is%3Aopen+is%3Aissue+label%3A%22Transform%3A+tokenizer%22+label%3A%22Type%3A+Enhancement%22) - [bugs](https://github.com/timberio/vector/issues?q=is%3Aopen+is%3Aissue+label%3A%22Transform%3A+tokenizer%22+label%3A%22Type%3A+Bug%22)
* [**Source code**](https://github.com/timberio/vector/tree/master/src/transform/tokenizer.rs)


[log_event]: "../../../about/data-model.md#log"
[sources]: "../../../usage/configuration/sources"
[transforms]: "../../../usage/configuration/transforms"
[config_composition]: "../../../usage/configuration/README.md#composition"
[monitoring_logs]: "../../../administration/moonitoring.md#logs"
[troubleshooting]: "../../../usages/guides/troubleshooting.md"
[search_forum]: "https://forum.vectorproject.io/search?expanded=true"
[community]: "https://vectorproject.io/community"
[grok_parser_transform]: "../../../usage/configuration/transform/grok_parser.md"
[lua_transform]: "../../../usage/configuration/transform/lua.md"
[regex_parser_transform]: "../../../usage/configuration/transform/regex_parser.md"

